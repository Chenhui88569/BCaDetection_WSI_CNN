{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing and Tile-structured dataset formation --Workflow\n",
    "## 1. Image preprocessing\n",
    "1. tile regular sampling\n",
    "2. labeling\n",
    "3. color space transformation\n",
    "4. remove non-tissue area<br>\n",
    "\n",
    "## 2. Filename handling\n",
    "To match the filenames of WSI with that of masks<br>\n",
    "benefit labeling process\n",
    "\n",
    "## 3. Tile-structured dataset formation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import os \n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "#used prior to CNN model training\n",
    "#four subtasks are included in function: sampling, non-tissue regions removing,\n",
    "#color space transformation and tile labeling\n",
    "#Raw tiles, unprocessed but labelled tiles,as well as processed and labelled tiles are stored \n",
    "\n",
    "def img_sampling_labeling(\n",
    "    input_path_WSI,input_path_mask,output_path_RawTile,output_path_processed_positive,output_path_processed_negative, \n",
    "    output_path_unprocessed_positive,output_path_unprocessed_negative):\n",
    "\n",
    "    positive_collection = []\n",
    "    negative_collection = []\n",
    "    non_tissue_collection = []\n",
    "    tile_size = (101, 101)\n",
    "    offset = (101, 101)\n",
    "    #remove and recreate directories \n",
    "    if  os.path.exists(output_path_RawTile) :\n",
    "        shutil.rmtree(output_path_RawTile)     \n",
    "    os.makedirs(output_path_RawTile)\n",
    "    if  os.path.exists(output_path_processed_positive) :\n",
    "        shutil.rmtree(output_path_processed_positive)     \n",
    "    os.makedirs( output_path_processed_positive)\n",
    "    if  os.path.exists(output_path_processed_negative) :\n",
    "        shutil.rmtree(output_path_processed_negative)     \n",
    "    os.makedirs(output_path_processed_negative)\n",
    "        \n",
    "    if  os.path.exists(output_path_unprocessed_positive) :\n",
    "        shutil.rmtree(output_path_unprocessed_positive)     \n",
    "    os.makedirs( output_path_unprocessed_positive)\n",
    "    if  os.path.exists(output_path_unprocessed_negative) :\n",
    "        shutil.rmtree(output_path_unprocessed_negative)     \n",
    "    os.makedirs(output_path_unprocessed_negative)\n",
    "    \n",
    "        \n",
    "    for imgname in os.listdir(input_path_WSI):\n",
    "        img_WSI = cv2.imread(os.path.join(input_path_WSI,imgname))\n",
    "        img_mask = cv2.imread(os.path.join(input_path_mask,imgname))\n",
    "        img_shape = img_WSI.shape\n",
    "        for i in range(int(math.ceil(img_shape[0]/(offset[1] * 1.0)))): #height\n",
    "            for j in range(int(math.ceil(img_shape[1]/(offset[0] * 1.0)))):#width\n",
    "                #for each tile\n",
    "                #step1. tile sampling\n",
    "                cropped_img_WSI = img_WSI[offset[1]*i:min(offset[1]*i+tile_size[1], img_shape[0]), offset[0]*j:min(offset[0]*j+tile_size[0], img_shape[1])]\n",
    "                cropped_img_mask = img_mask[offset[1]*i:min(offset[1]*i+tile_size[1], img_shape[0]), offset[0]*j:min(offset[0]*j+tile_size[0], img_shape[1])]\n",
    "                #save plain tiles\n",
    "                cv2.imwrite(output_path_RawTile + '\\\\'+ imgname +'_tile_'+ str(i)+\"_\"+ str(j)+'.png', cropped_img_WSI)\n",
    "                if cropped_img_WSI is not None:#checkpoint\n",
    "                    cropped_image_WSI_01 = cropped_img_WSI/255 \n",
    "                    cropped_image_WSI_img_01_mean = cropped_image_WSI_01.mean()\n",
    "                    cropped_image_WSI_img_01_std = cropped_image_WSI_01.std() \n",
    "                    #step2.Remove non_tissue\n",
    "                    if cropped_image_WSI_img_01_mean >= 0.85  and cropped_image_WSI_img_01_std <= 0.1: #more strict \n",
    "                         non_tissue_collection.append( imgname+'_'+str(i)+\"_\"+ str(j))\n",
    "                    else:\n",
    "                        #step3.  color space transoformation : RGB to YUV\n",
    "                        # normalization and standardization are achieved using imageGenerator \n",
    "                        #img_processed = ColorSpaceTransformaton_Standardization_Normalization(cropped_img_WSI)\n",
    "                        img_processed = cv2.cvtColor(cropped_img_WSI,cv2.COLOR_RGB2YUV)\n",
    "                         #step4. labeling according to binary mask\n",
    "                        a = np.mean(cropped_img_mask[:,:,0])/255 # binary mask 0ï¼šwhite; 1: black\n",
    "                        if a >= 0.55:#60% white(positive) #more slack\n",
    "                            positive_collection.append( imgname+'_'+str(i)+\"_\"+ str(j))\n",
    "                            #save to local positive folder\n",
    "                            cv2.imwrite(output_path_processed_positive + '\\\\'+ imgname[0:-4] +'_tile_'+ str(i)+\"_\"+ str(j)+'.png', img_processed)\n",
    "                            cv2.imwrite(output_path_unprocessed_positive + '\\\\'+ imgname[0:-4] +'_tile_'+ str(i)+\"_\"+ str(j)+'.png', cropped_img_WSI )\n",
    "                         \n",
    "                        else:\n",
    "                             #save to negative folder\n",
    "                            cv2.imwrite(output_path_processed_negative + '\\\\'+ imgname[0:-4] +'_tile_'+ str(i)+\"_\"+ str(j)+'.png', img_processed)\n",
    "                            cv2.imwrite(output_path_unprocessed_negative + '\\\\'+ imgname[0:-4] +'_tile_'+ str(i)+\"_\"+ str(j)+'.png', cropped_img_WSI )\n",
    "                            negative_collection.append(imgname+'_'+str(i)+\"_\"+ str(j)) \n",
    "                else:\n",
    "                    non_tissue_collection.append(dirname+'_'+str(i)+\"_\"+ str(j))\n",
    "    return positive_collection, negative_collection, non_tissue_collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CWRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path_training_WSI_CWRU = r'\\ECSE484_Fall2020\\training_2020\\CWRU_imgs_idx8'\n",
    "original_path_training_mask_CWRU = r'\\ECSE484_Fall2020\\training_2020\\CWRU_masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_RawTile = r'ECSE484_Fall2020\\training_2020\\CWRU_RawTile'\n",
    "output_path_processed_positive = r'\\ECSE484_Fall2020\\training_2020\\CWRU_processed_tiles\\positive'\n",
    "output_path_processed_negative = r'\\ECSE484_Fall2020\\training_2020\\CWRU_processed_tiles\\negative'\n",
    "output_path_unprocessed_positive = r'\\ECSE484_Fall2020\\training_2020\\CWRU_unprocessed_tiles\\positive'\n",
    "output_path_unprocessed_negative = r'\\ECSE484_Fall2020\\training_2020\\CWRU_unprocessed_tiles\\negative'\n",
    "input_path_WSI = original_path_training_WSI_CWRU\n",
    "input_path_mask =  original_path_training_mask_CWRU\n",
    "positive_collection, negative_collection, non_tissue_collection = img_sampling_labeling(\n",
    "    input_path_WSI,input_path_mask,output_path_RawTile,output_path_processed_positive,output_path_processed_negative, \n",
    "    output_path_unprocessed_positive,output_path_unprocessed_negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CWRU image tiles in total: 101576\n",
      "Number of CWRU positive tiles: 6821\n",
      "Number of CWRU negative tiles: 31526\n",
      "Number of CWRU non-tissue tiles: 63229\n"
     ]
    }
   ],
   "source": [
    "print('Number of CWRU image tiles in total:', len(non_tissue_collection )+\n",
    "      len(positive_collection)+len(negative_collection) )\n",
    "print('Number of CWRU positive tiles:', len(positive_collection))\n",
    "print('Number of CWRU negative tiles:', len(negative_collection))\n",
    "print('Number of CWRU non-tissue tiles:', len(non_tissue_collection ))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path_training_mask_HUP_1 = r'\\ECSE484_Fall2020\\training_2020\\HUP_masks_part1' \n",
    "original_path_training_mask_HUP_2 = r'\\ECSE484_Fall2020\\training_2020\\HUP_mask_part2'\n",
    "original_path_training_WSI_HUP_1  = r'\\ECSE484_Fall2020\\training_2020\\HUP_imgs_idx5_Part_1'\n",
    "original_path_training_WSI_HUP_2 = r'\\ECSE484_Fall2020\\training_2020\\HUP_imgs_idx5_Part_2'\n",
    "original_path_training_WSI_HUP = r'\\ECSE484_Fall2020\\training_2020\\HUP_imgs'\n",
    "original_path_training_mask_HUP = r'\\ECSE484_Fall2020\\training_2020\\HUP_masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_RawTile = r'\\ECSE484_Fall2020\\training_2020\\HUP_RawTile'\n",
    "output_path_processed_positive = r'\\ECSE484_Fall2020\\training_2020\\HUP_processed_tiles\\positive'\n",
    "output_path_processed_negative = r'\\ECSE484_Fall2020\\training_2020\\HUP_processed_tiles\\negative'\n",
    "output_path_unprocessed_positive = r'\\ECSE484_Fall2020\\training_2020\\HUP_unprocessed_tiles\\positive'\n",
    "output_path_unprocessed_negative = r'\\ECSE484_Fall2020\\training_2020\\HUP_unprocessed_tiles\\negative'\n",
    "input_path_WSI = original_path_training_WSI_HUP\n",
    "input_path_mask =  original_path_training_mask_HUP\n",
    "positive_collection, negative_collection, non_tissue_collection = img_sampling_labeling(\n",
    "    input_path_WSI,input_path_mask,output_path_RawTile,output_path_processed_positive,output_path_processed_negative, \n",
    "    output_path_unprocessed_positive,output_path_unprocessed_negative) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "temp = os.listdir(output_path_processed_positive)\n",
    "a = cv2.imread(os.path.join(output_path_processed_positive,temp[0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of HUP image tiles in total: 172197\n",
      "Number of HUP positive tiles: 12628\n",
      "Number of HUP negative tiles: 49716\n",
      "Number of HUP non-tissue tiles: 109853\n"
     ]
    }
   ],
   "source": [
    "print('Number of HUP image tiles in total:', len(non_tissue_collection )+\n",
    "      len(positive_collection)+len(negative_collection) )\n",
    "print('Number of HUP positive tiles:', len(positive_collection))\n",
    "print('Number of HUP negative tiles:', len(negative_collection))\n",
    "print('Number of HUP non-tissue tiles:', len(non_tissue_collection ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path_training_WSI_TCGA = r'\\ECSE484_Fall2020\\training_2020\\TCGA_imgs_idx5'\n",
    "original_path_training_mask_TCGA = r'\\ECSE484_Fall2020\\training_2020\\TCGA_masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_RawTile = r'\\ECSE484_Fall2020\\training_2020\\TCGA_RawTile'\n",
    "output_path_processed_positive = r'\\ECSE484_Fall2020\\training_2020\\TCGA_processed_tiles\\positive'\n",
    "output_path_processed_negative = r'\\ECSE484_Fall2020\\training_2020\\TCGA_processed_tiles\\negative'\n",
    "output_path_unprocessed_positive = r'\\ECSE484_Fall2020\\training_2020\\TCGA_unprocessed_tiles\\positive'\n",
    "output_path_unprocessed_negative = r'\\ECSE484_Fall2020\\training_2020\\TCGA_unprocessed_tiles\\negative'\n",
    "input_path_WSI = original_path_training_WSI_TCGA\n",
    "input_path_mask =  original_path_training_mask_TCGA\n",
    "positive_collection, negative_collection, non_tissue_collection = img_sampling_labeling(\n",
    "    input_path_WSI,input_path_mask,output_path_RawTile,output_path_processed_positive,output_path_processed_negative, \n",
    "    output_path_unprocessed_positive,output_path_unprocessed_negative) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TCGA image tiles in total: 132110\n",
      "Number of TCGA positive tiles: 24733\n",
      "Number of TCGA negative tiles: 30365\n",
      "Number of TCGA non-tissue tiles: 77012\n"
     ]
    }
   ],
   "source": [
    "print('Number of TCGA image tiles in total:', len(non_tissue_collection )+\n",
    "      len(positive_collection)+len(negative_collection) )\n",
    "print('Number of TCGA positive tiles:', len(positive_collection))\n",
    "print('Number of TCGA negative tiles:', len(negative_collection))\n",
    "print('Number of TCGA non-tissue tiles:', len(non_tissue_collection ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CINJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path_training_WSI_CINJ = r'\\ECSE484_Fall2020\\testing_2020\\CINJ_imgs_idx5'\n",
    "original_path_training_mask_CINJ = r'\\ECSE484_Fall2020\\testing_2020\\CINJ_masks_HG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_RawTile = r'\\ECSE484_Fall2020\\testing_2020\\CINJ_RawTile'\n",
    "output_path_processed_positive = r'\\ECSE484_Fall2020\\testing_2020\\CINJ_processed_tiles\\positive'\n",
    "output_path_processed_negative = r'\\ECSE484_Fall2020\\testing_2020\\CINJ_processed_tiles\\negative'\n",
    "output_path_unprocessed_positive = r'\\ECSE484_Fall2020\\testing_2020\\CINJ_unprocessed_tiles\\positive'\n",
    "output_path_unprocessed_negative = r'\\ECSE484_Fall2020\\testing_2020\\CINJ_unprocessed_tiles\\negative'\n",
    "input_path_WSI = original_path_training_WSI_CINJ\n",
    "input_path_mask =  original_path_training_mask_CINJ\n",
    "positive_collection, negative_collection, non_tissue_collection = img_sampling_labeling(\n",
    "    input_path_WSI,input_path_mask,output_path_RawTile,output_path_processed_positive,output_path_processed_negative, \n",
    "    output_path_unprocessed_positive,output_path_unprocessed_negative) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CINJ image tiles in total: 28994\n",
      "Number of CINJ positive tiles: 3800\n",
      "Number of CINJ negative tiles: 10330\n",
      "Number of CINJ non-tissue tiles: 14864\n"
     ]
    }
   ],
   "source": [
    "print('Number of CINJ image tiles in total:', len(non_tissue_collection )+\n",
    "      len(positive_collection)+len(negative_collection) )\n",
    "print('Number of CINJ positive tiles:', len(positive_collection))\n",
    "print('Number of CINJ negative tiles:', len(negative_collection))\n",
    "print('Number of CINJ non-tissue tiles:', len(non_tissue_collection ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filename Handling\n",
    "\n",
    "To match the filename of WSI with that of masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the alphebats in the filename\n",
    "import re\n",
    "def RemoveAlphebats(input_path):\n",
    "    for old_imgname in os.listdir(input_path):\n",
    "        new_imgname = ''.join([i for i in old_imgname if i.isnumeric()]);  \n",
    "        os.rename(os.path.join(input_path,old_imgname), os.path.join(input_path,new_imgname+'.png'))#suffix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only ForHUP_imgs_idx5_Part_1 and HUP_imgs_idx5_Part_1 \n",
    "#only For original_path_training_WSI_HUP_1 , original_path_training_WSI_HUP_2 \n",
    "# and original_path_validation_WSI_CINJ\n",
    "#operation only once !!!\n",
    "import os\n",
    "def RemoveLas5(input_path):\n",
    "    for old_imgname in os.listdir(input_path):\n",
    "        new_imgname_onlynum = ''.join([i for i in old_imgname if i.isnumeric()]);  #re.sub\n",
    "        new_imgname = new_imgname_onlynum[:-1] \n",
    "        os.rename(os.path.join(input_path,old_imgname), os.path.join(input_path,new_imgname+'.png'))#suffix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path_validation_WSI_CINJ = r'\\ECSE484_Fall2020\\testing_2020\\CINJ_imgs_idx5'\n",
    "original_path_training_mask_HUP_1 = r'\\ECSE484_Fall2020\\training_2020\\HUP_masks_part1' \n",
    "original_path_training_mask_HUP_2 = r'\\ECSE484_Fall2020\\training_2020\\HUP_mask_part2'\n",
    "original_path_training_WSI_HUP_1  = r'\\paper_material\\ECSE484_Fall2020\\training_2020\\HUP_imgs_idx5_Part_1'\n",
    "original_path_training_WSI_HUP_2 = r'\\paper_material\\ECSE484_Fall2020\\training_2020\\HUP_imgs_idx5_Part_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "RemoveAlphebats(original_path_validation_WSI_CINJ)\n",
    "RemoveAlphebats(original_path_training_mask_HUP_1)\n",
    "RemoveAlphebats(original_path_training_mask_HUP_2)\n",
    "RemoveAlphebats(original_path_training_WSI_HUP_1)\n",
    "RemoveAlphebats(original_path_training_WSI_HUP_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#operation only once !!!\n",
    "RemoveLas5(original_path_training_WSI_HUP_1)\n",
    "RemoveLas5(original_path_training_WSI_HUP_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#operation only once !!!\n",
    "RemoveLas5(original_path_validation_WSI_CINJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent filenames:  0\n"
     ]
    }
   ],
   "source": [
    "# check if there is inconsistency in filenames of WSI and mask\n",
    "original_path_training_WSI_CWRU = r'\\ECSE484_Fall2020\\training_2020\\CWRU_imgs_idx8'\n",
    "original_path_training_mask_CWRU = r'\\ECSE484_Fall2020\\training_2020\\CWRU_masks'\n",
    "# Find inconsistent filenames\n",
    "import numpy as np\n",
    "import re\n",
    "training_WSI_CWRU_filenames = np.array(os.listdir(original_path_training_WSI_CWRU))#need to be converted into np.array\n",
    "training_mask_CWRU_filenames =  np.array(os.listdir(original_path_training_mask_CWRU))\n",
    "training_WSI_CWRU_filenames  == training_mask_CWRU_filenames\n",
    "Inconsistency = np.where(training_WSI_CWRU_filenames != training_mask_CWRU_filenames) #return tuple\n",
    "print('Number of inconsistent filenames: ',len(Inconsistency[0]))\n",
    "for  i in Inconsistency[0]:\n",
    "    print(training_WSI_CWRU_filenames[i])\n",
    "    print(training_mask_CWRU_filenames[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Dataset Construction:\n",
    "\n",
    "### Case 1 \n",
    "\n",
    "$$\n",
    "\\begin{array}{|l|l|l|l|l|}\n",
    "\\hline & \\text { CWRU } & \\text { HUP } & \\text { TCGA } & \\text { CINJ } \\\\\n",
    "\\hline \\text { Training:positive } & 3000 & 2000 & 2000 & 0 \\\\\n",
    "\\hline \\text { Training:negative } & 3000 & 2000 & 2000 & 0 \\\\\n",
    "\\hline \\text { Training: total } & 6000 & 4000 & 4000 & 0 \\\\\n",
    "\\hline \\text { Validation:positive } & 500 & 500 & 500 & 0 \\\\\n",
    "\\hline \\text { Validation:negative } & 500 & 500 & 500 & 0 \\\\\n",
    "\\hline \\text { Validation: total } & 1000 & 1000 & 1000 & 0 \\\\\n",
    "\\hline \\text { Testing:positive } & 0 & 0 & 0 & 1500 \\\\\n",
    "\\hline \\text { Testing:negative } & 0 & 0 & 0 & 1500 \\\\\n",
    "\\hline \\text { Testing:total } & 0 & 0 & 0 & 3000 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2 \n",
    "\n",
    "$$\n",
    "\\begin{array}{|l|l|l|l|l|}\n",
    "\\hline & \\text { CWRU } & \\text { HUP } & \\text { TCGA } & \\text { CINJ } \\\\\n",
    "\\hline \\text { Training:positive } & 1750 & 1750 & 1750 & 1750 \\\\\n",
    "\\hline \\text { Training:negative } & 1750 & 1750 & 1750 & 1750 \\\\\n",
    "\\hline \\text { Total training } & 3500 & 3500 & 3500 & 3500 \\\\\n",
    "\\hline \\text { Validation:positive } & 375 & 375 & 375 & 375 \\\\\n",
    "\\hline \\text { Validation:negative } & 375 & 375 & 375 & 375 \\\\\n",
    "\\hline \\text { Validation:total } & 750 & 750 & 750 & 750 \\\\\n",
    "\\hline \\text { Testing:positive } & 0 & 0 & 0 & 1500 \\\\\n",
    "\\hline \\text { Testing:negative } & 0 & 0 & 0 & 1500 \\\\\n",
    "\\hline \\text { Testing: total } & 0 & 0 & 0 & 3000 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation set construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset1---delete and recreate `dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "output_path_training = r'\\ECSE484_Fall2020\\training_for_CNN'\n",
    "output_path_validation = r'\\ECSE484_Fall2020\\validation_for_CNN'\n",
    "output_positive_path_training = os.path.join(output_path_training,'positive' ) \n",
    "output_negative_path_training = os.path.join(output_path_training,'negative' ) \n",
    "output_positive_path_validation = os.path.join(output_path_validation,'positive' ) \n",
    "output_negative_path_validation = os.path.join(output_path_validation ,'negative' ) \n",
    "if  os.path.exists(output_path_training) :\n",
    "        shutil.rmtree(output_path_training)     \n",
    "os.makedirs(output_positive_path_training, exist_ok=True)\n",
    "    \n",
    "os.makedirs(output_negative_path_training, exist_ok=True)\n",
    "if  os.path.exists(output_path_validation) :\n",
    "        shutil.rmtree(output_path_validation)  \n",
    "        \n",
    "os.makedirs(output_positive_path_validation, exist_ok=True)#intermediate level\n",
    "os.makedirs(output_negative_path_validation, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset2---delete and recreate `dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil\n",
    "output_path_training = r'\\ECSE484_Fall2020\\training_for_CNN_2'\n",
    "output_path_validation = r'\\ECSE484_Fall2020\\validation_for_CNN_2'\n",
    "output_path_testing = r'\\ECSE484_Fall2020\\testing_for_CNN_2'\n",
    "output_positive_path_training = os.path.join(output_path_training,'positive' ) \n",
    "output_negative_path_training = os.path.join(output_path_training,'negative' ) \n",
    "output_positive_path_validation = os.path.join(output_path_validation,'positive' ) \n",
    "output_negative_path_validation = os.path.join(output_path_validation ,'negative' ) \n",
    "output_positive_path_testing = os.path.join(output_path_testing,'positive' ) \n",
    "output_negative_path_testing = os.path.join(output_path_testing ,'negative' ) \n",
    "if  os.path.exists(output_path_training) :\n",
    "        shutil.rmtree(output_path_training)  \n",
    "        \n",
    "if  os.path.exists(output_path_validation) :\n",
    "        shutil.rmtree(output_path_validation)  \n",
    "if  os.path.exists(output_path_testing) :\n",
    "        shutil.rmtree(output_path_testing)  \n",
    "os.makedirs(output_positive_path_training, exist_ok=True)\n",
    "os.makedirs(output_negative_path_training)\n",
    "   \n",
    "        \n",
    "os.makedirs(output_positive_path_validation, exist_ok=True)#intermediate level\n",
    "os.makedirs(output_negative_path_validation)\n",
    "\n",
    "os.makedirs(output_positive_path_testing, exist_ok=True)#intermediate level\n",
    "os.makedirs(output_negative_path_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TransportFilesToDataset`  <br>\n",
    "1.distribute files from CWRU, HUP, TCGA dataset to training and validation set with defined split ratio<br> 2. used in constructing both dataset1 and dataset2 <br> \n",
    "Only CINJ is used in building testing set <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def TransportFilesToDataset(input_path,output_path_training,\n",
    "                            output_path_validation,HalfNumRequired_training, HalfNumRequired_validation):\n",
    "#only for training and validation set\n",
    "#input_path and output_path are parent directory path of 'positive' and 'negative' directory\n",
    "    input_positive_path = os.path.join(input_path,'positive' )\n",
    "    input_negative_path = os.path.join(input_path,'negative' ) \n",
    "    output_positive_path_training = os.path.join(output_path_training,'positive' ) \n",
    "    output_negative_path_training = os.path.join(output_path_training,'negative' ) \n",
    "    output_positive_path_validation = os.path.join(output_path_validation,'positive' ) \n",
    "    output_negative_path_validation = os.path.join(output_path_validation ,'negative' ) \n",
    "    \n",
    "    input_positive_files = os.listdir( input_positive_path    )\n",
    "    input_negative_files = os.listdir( input_negative_path    )\n",
    "    randomList_positive = []\n",
    "    randomList_negative = []\n",
    "    randomList_positive_Training = []\n",
    "    randomList_positive_negative = []\n",
    "    #extract random index of input postivie and negative folders\n",
    "    randomList_positive = random.sample(range(0, len(input_positive_files)), \n",
    "                                         HalfNumRequired_training + HalfNumRequired_validation    )\n",
    "    randomList_negative = random.sample(range(0, len(input_negative_files)), \n",
    "                                        HalfNumRequired_training + HalfNumRequired_validation  )\n",
    "    \n",
    "    random.shuffle(randomList_positive)\n",
    "    random.shuffle(randomList_negative)\n",
    "    randomList_positive_training = randomList_positive[0:  HalfNumRequired_training    ]\n",
    "    randomList_positive_validation = randomList_positive[ HalfNumRequired_training :]\n",
    "    randomList_negative_training = randomList_negative[0: HalfNumRequired_training ]\n",
    "    randomList_negative_validation = randomList_negative[HalfNumRequired_training :]\n",
    "\n",
    "    \n",
    "    for idx, ran_num in enumerate(randomList_positive_training):\n",
    "        src = os.path.join(input_positive_path, input_positive_files[ran_num]  )\n",
    "        shutil.copy2(   src ,      output_positive_path_training)#dst could be directory or complete target filename\n",
    "    \n",
    "    for idx, ran_num in enumerate(  randomList_negative_training):\n",
    "        src = os.path.join(input_negative_path,input_negative_files[ran_num]  )\n",
    "        shutil.copy2(   src ,      output_negative_path_training) \n",
    "        \n",
    "    for idx, ran_num in enumerate(  randomList_positive_validation):\n",
    "        src = os.path.join(input_positive_path, input_positive_files[ran_num]  )\n",
    "        shutil.copy2(   src ,     output_positive_path_validation)   \n",
    "        \n",
    "    for idx, ran_num in enumerate(     randomList_negative_validation):\n",
    "        src = os.path.join(input_negative_path,input_negative_files[ran_num]  )\n",
    "        shutil.copy2(   src ,      output_negative_path_validation) \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "main_path_training = r'D:\\semester 1th\\intro to bioinfo\\paper_material\\ECSE484_Fall2020\\training_2020'\n",
    "CWRU_path_processed = os.path.join(main_path_training , 'CWRU_processed_tiles')\n",
    "HUP_path_processed  = os.path.join(main_path_training , 'HUP_processed_tiles')\n",
    "TCGA_path_processed = os.path.join(main_path_training , 'TCGA_processed_tiles')\n",
    "CINJ_path_processed = os.path.join(main_path_training , 'CINJ_processed_tiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CWRU_dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = CWRU_path_processed\n",
    "output_path_training = r'\\ECSE484_Fall2020\\training_for_CNN'\n",
    "output_path_validation = r'\\ECSE484_Fall2020\\validation_for_CNN'\n",
    "TotalNumRequired_training = 3000\n",
    "TotalNumRequired_validation = 500\n",
    "TransportFilesToDataset(input_path,output_path_training,output_path_validation,\n",
    "                        TotalNumRequired_training, TotalNumRequired_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CWRU_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = CWRU_path_processed\n",
    "output_path_training = r'\\ECSE484_Fall2020\\training_for_CNN_2'\n",
    "output_path_validation = r'\\ECSE484_Fall2020\\validation_for_CNN_2'\n",
    "TotalNumRequired_training = 1750\n",
    "TotalNumRequired_validation = 375\n",
    "TransportFilesToDataset(input_path,output_path_training,output_path_validation,\n",
    "                        TotalNumRequired_training, TotalNumRequired_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HUP_dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = HUP_path_processed\n",
    "output_path_training = r'\\ECSE484_Fall2020\\training_for_CNN'\n",
    "output_path_validation = r'\\ECSE484_Fall2020\\validation_for_CNN'\n",
    "TotalNumRequired_training = 2000\n",
    "TotalNumRequired_validation = 500\n",
    "TransportFilesToDataset(input_path,output_path_training,output_path_validation,\n",
    "                        TotalNumRequired_training, TotalNumRequired_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HUP_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = HUP_path_processed\n",
    "output_path_training = r'\\ECSE484_Fall2020\\training_for_CNN_2'\n",
    "output_path_validation = r'\\ECSE484_Fall2020\\validation_for_CNN_2'\n",
    "TotalNumRequired_training = 1750\n",
    "TotalNumRequired_validation = 375\n",
    "TransportFilesToDataset(input_path,output_path_training,output_path_validation,\n",
    "                        TotalNumRequired_training, TotalNumRequired_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCGA_dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = TCGA_path_processed\n",
    "output_path_training = r'\\ECSE484_Fall2020\\training_for_CNN'\n",
    "output_path_validation = r'\\ECSE484_Fall2020\\validation_for_CNN'\n",
    "TotalNumRequired_training = 2000\n",
    "TotalNumRequired_validation = 500\n",
    "TransportFilesToDataset(input_path,output_path_training,output_path_validation,\n",
    "                        TotalNumRequired_training, TotalNumRequired_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCGA_dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = TCGA_path_processed\n",
    "output_path_training = r'\\ECSE484_Fall2020\\training_for_CNN_2'\n",
    "output_path_validation = r'\\ECSE484_Fall2020\\validation_for_CNN_2'\n",
    "TotalNumRequired_training =  1750\n",
    "TotalNumRequired_validation = 375\n",
    "TransportFilesToDataset(input_path,output_path_training,output_path_validation,\n",
    "                        TotalNumRequired_training, TotalNumRequired_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CINJ_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = CINJ_path_processed\n",
    "output_path_training = r'\\ECSE484_Fall2020\\training_for_CNN_2'\n",
    "output_path_validation = r'\\ECSE484_Fall2020\\validation_for_CNN_2'\n",
    "output_path_testing = r'\\ECSE484_Fall2020\\testing_for_CNN_2'\n",
    "HalfNumRequired_training = 1750\n",
    "HalfNumRequired_validation = 375\n",
    "HalfNumRequired_testing = 375\n",
    "TransportFilesToAllDataset(input_path,output_path_training,output_path_validation,output_path_testing,\n",
    "                        HalfNumRequired_training, HalfNumRequired_validation,HalfNumRequired_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "num_test = os.listdir( os.path.join(output_path_training, 'negative'))\n",
    "print(len(num_test))\n",
    "print(len(set(num_test))) #check the exsitence of repetitive files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TransportFilesToDataset_dataset2_CINJ` used for CINJ only<br>\n",
    "As to dataset2, CINJ dataset is divided into three parts constituting training , validation and testing set respectivey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransportFilesToDataset_dataset2_CINJ(input_path, output_path_testing, \n",
    "                                   output_path_training,output_path_validation,\n",
    "                                   HalfNumRequired_training, HalfNumRequired_validation):\n",
    "#input_path and output_path are parent directory path of 'positive' and 'negative' directory\n",
    "    #path\n",
    "    input_positive_path = os.path.join(input_path,'positive' )\n",
    "    input_negative_path = os.path.join(input_path,'negative' ) \n",
    "    output_positive_path_testing = os.path.join(output_path_testing,'positive' ) #input actually\n",
    "    output_negative_path_testing = os.path.join(output_path_testing ,'negative' ) #input actually\n",
    "   \n",
    "    output_positive_path_training = os.path.join(output_path_training,'positive' ) \n",
    "    output_negative_path_training = os.path.join(output_path_training,'negative' )\n",
    "    \n",
    "    output_positive_path_validation = os.path.join(output_path_validation,'positive' ) \n",
    "    output_negative_path_validation = os.path.join(output_path_validation ,'negative' )\n",
    "   \n",
    "    #read filenames\n",
    "    input_positive_files = os.listdir( input_positive_path    )\n",
    "    input_negative_files = os.listdir( input_negative_path    )\n",
    "    output_positive_testing_files = os.listdir(output_positive_path_testing ) \n",
    "    output_negative_testing_files = os.listdir(output_positive_path_testing ) \n",
    "    input_positive_files_2 = input_positive_files\n",
    "    input_negative_files_2 = input_negative_files \n",
    "    #files already assigned to testing set will not be used in training and validation set \n",
    "    for item in output_positive_testing_files:\n",
    "        if item  in input_positive_files_2:\n",
    "            input_positive_files_2.remove(item )\n",
    "    for item in output_negative_testing_files:\n",
    "        if item  in input_negative_files_2:\n",
    "            input_negative_files_2.remove(item )\n",
    "   \n",
    "\n",
    "    randomList_positive = []\n",
    "    randomList_negative = []\n",
    "    #extract random index from input postivie and negative folders\n",
    "    randomList_positive = random.sample(range(0, len(input_positive_files_2)), \n",
    "                                         HalfNumRequired_training + HalfNumRequired_validation    )\n",
    "    randomList_negative = random.sample(range(0, len(input_positive_files_2)), \n",
    "                                        HalfNumRequired_training + HalfNumRequired_validation  )\n",
    "    \n",
    "    random.shuffle(randomList_positive)\n",
    "    random.shuffle(randomList_negative)\n",
    "    #assign files to training and validation set \n",
    "    randomList_positive_training = randomList_positive[0:  HalfNumRequired_training    ]\n",
    "    randomList_positive_validation = randomList_positive[ HalfNumRequired_training :]\n",
    "    randomList_negative_training = randomList_negative[0: HalfNumRequired_training ]\n",
    "    randomList_negative_validation = randomList_negative[HalfNumRequired_training :]\n",
    "\n",
    "    #Given the filename lists for training and validation sets,  copy files from path of processed CINJ images tiles to \n",
    "    #the paths of training and validation set\n",
    "    for idx, ran_num in enumerate(randomList_positive_training):\n",
    "        src = os.path.join(input_positive_path,  input_positive_files_2[ran_num]  )\n",
    "        shutil.copy2(   src ,      output_positive_path_training)#dst could be directory or complete target filename\n",
    "    \n",
    "    for idx, ran_num in enumerate(  randomList_negative_training):\n",
    "        src = os.path.join(input_negative_path, input_negative_files_2[ran_num]  )\n",
    "        shutil.copy2(   src ,      output_negative_path_training) \n",
    "        \n",
    "    for idx, ran_num in enumerate(  randomList_positive_validation):\n",
    "        src = os.path.join(input_positive_path,   input_positive_files_2[ran_num]  )\n",
    "        shutil.copy2(   src ,     output_positive_path_validation)   \n",
    "        \n",
    "    for idx, ran_num in enumerate(     randomList_negative_validation):\n",
    "        src = os.path.join(input_negative_path,input_negative_files_2[ran_num]  )\n",
    "        shutil.copy2(   src ,      output_negative_path_validation) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "main_path_training = r'\\ECSE484_Fall2020\\testing_2020'\n",
    "CINJ_path_processed = os.path.join(main_path_training , 'CINJ_processed_tiles')\n",
    "input_path = CINJ_path_processed\n",
    "output_path_testing = r'\\ECSE484_Fall2020\\testing_for_CNN_2'\n",
    "output_path_training = r'\\ECSE484_Fall2020\\training_for_CNN_2'\n",
    "output_path_validation = r'=\\ECSE484_Fall2020\\validation_for_CNN_2'\n",
    "HalfNumRequired_training = 1750\n",
    "HalfNumRequired_validation = 375\n",
    "\n",
    "TransportFilesToDataset_dataset2_CINJ(input_path, output_path_testing, \n",
    "                                   output_path_training,output_path_validation,\n",
    "                                   HalfNumRequired_training, HalfNumRequired_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing set\n",
    "only CINJ is used in testing set<br>\n",
    "The testing set of both dataset1 and dataset2 is the same "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TransportFilesToTestDataset` : only for forming testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def TransportFilesToTestDataset(input_path,output_path_testing,HalfNumRequired_testing):\n",
    "#input_path and output_path are parent directory path of 'positive' and 'negative' directory\n",
    "    input_positive_path = os.path.join(input_path,'positive' )\n",
    "    input_negative_path = os.path.join(input_path,'negative' ) \n",
    "    output_positive_path_testing = os.path.join(output_path_testing,'positive' ) \n",
    "    output_negative_path_testing = os.path.join(output_path_testing,'negative' ) \n",
    "    \n",
    "    input_positive_files = os.listdir( input_positive_path    )\n",
    "    input_negative_files = os.listdir( input_negative_path    )\n",
    "    randomList_positive = []\n",
    "    randomList_negative = []\n",
    "   \n",
    "    #extract random index of input postivie and negative folders\n",
    "    randomList_positive = random.sample(range(0, len(input_positive_files)), \n",
    "                                         HalfNumRequired_testing   )\n",
    "    randomList_negative = random.sample(range(0, len(input_negative_files)), \n",
    "                                        HalfNumRequired_testing )\n",
    "    \n",
    " \n",
    "    \n",
    "    for idx, ran_num in enumerate(randomList_positive):\n",
    "        src = os.path.join(input_positive_path, input_positive_files[ran_num]  )\n",
    "        shutil.copy2(   src ,     output_positive_path_testing)#dst could be directory or complete target filename\n",
    "    \n",
    "    for idx, ran_num in enumerate(  randomList_negative):\n",
    "        src = os.path.join(input_negative_path,input_negative_files[ran_num]  )\n",
    "        shutil.copy2(   src ,      output_negative_path_testing) \n",
    "        \n",
    "     \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "main_path_training = r'\\ECSE484_Fall2020\\testing_2020'\n",
    "CINJ_path_processed = os.path.join(main_path_training , 'CINJ_processed_tiles')\n",
    "input_path = CINJ_path_processed\n",
    "output_path_testing = r'\\ECSE484_Fall2020\\testing_for_CNN'\n",
    " \n",
    "if  os.path.exists(output_path_testing) :\n",
    "        shutil.rmtree(output_path_testing)  \n",
    "os.makedirs(os.path.join(output_path_testing ,'positive'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path_testing ,'negative'))\n",
    "\n",
    "HalfNumRequired_testing = 1500\n",
    "TransportFilesToTestDataset(input_path,output_path_testing,HalfNumRequired_testing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
